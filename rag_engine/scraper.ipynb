{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "import yt_dlp\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(id: str) -> None:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(\n",
    "        id, languages=('en', 'en-US', 'en-GB'))\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(url):\n",
    "    print(\"in download_audio\")\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            },\n",
    "            {\n",
    "                'key': 'FFmpegSplitChapters',  # Adding split chapters processor\n",
    "                'force_keyframes': True,  # Optional: force keyframes at the start of each chapter\n",
    "                }],\n",
    "            'noplaylist': True,\n",
    "            'writeinfojson': True,  # Optional: write metadata into a JSON file\n",
    "            'writeannotations': True,  # Optional: write annotations into a file\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "    except Exception as e:\n",
    "        print(\"Error downloading audio: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(transcript, start_time, end_time):\n",
    "    # Initialize an empty string to hold the extracted text\n",
    "    extracted_text = \"\"\n",
    "    \n",
    "    # Loop through each entry in the transcript\n",
    "    for entry in transcript:\n",
    "        # Calculate the end time of the current entry\n",
    "        entry_end_time = entry['start'] + entry['duration']\n",
    "        \n",
    "        # Check if the entry overlaps with the given time range\n",
    "        if entry['start'] < end_time and entry_end_time > start_time:\n",
    "            # Add the text to the extracted text string\n",
    "            extracted_text += entry['text'] + \" \"\n",
    "    \n",
    "    return extracted_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id is: yNuLPWu38IU&ab_channel=NorgesBankInvestmentManagement\n",
      "in download_audio\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=yNuLPWu38IU&ab_channel=NorgesBankInvestmentManagement\n",
      "[youtube] yNuLPWu38IU: Downloading webpage\n",
      "[youtube] yNuLPWu38IU: Downloading ios player API JSON\n",
      "[youtube] yNuLPWu38IU: Downloading android player API JSON\n",
      "[youtube] yNuLPWu38IU: Downloading m3u8 information\n",
      "[info] yNuLPWu38IU: Downloading 1 format(s): 251\n",
      "[info] Writing video metadata as JSON to: Satya Nadella - CEO of Microsoft ｜ In Good Company ｜ Podcast ｜ Norges Bank Investment Management [yNuLPWu38IU].info.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    columns = ['channel', 'episode', 'chapter', 'start_time', 'end_time', 'text', 'file_name_prefix', 'prev_index', 'next_index']\n",
    "    all_results = []  # Start with an empty list to store dictionaries\n",
    "\n",
    "    video_urls = []\n",
    "    video_urls.extend([{\"link\": \"https://www.youtube.com/watch?v=yNuLPWu38IU&ab_channel=NorgesBankInvestmentManagement\", \"channel\": \"In Good Company\", \"episode\": \"Satya Nadella - CEO of Microsoft | In Good Company | Podcast | Norges Bank Investment Management\"},\n",
    "                      {\"link\": \"https://www.youtube.com/watch?v=8USI98_5GeU&ab_channel=TalkingSasquach\", \"channel\": \"Talking Sasquatch\", \"episode\": \"Momentum Firmware for Flipper Zero : The Next Generation of Flipper Custom Firmware!!\"}])\n",
    "\n",
    "    episodes_to_transcripts = {}\n",
    "\n",
    "    curr_base_idx = 0\n",
    "\n",
    "    for video in video_urls:\n",
    "        episode = video['episode']\n",
    "        channel = video['channel']\n",
    "        id = video['link'].split(\"v=\")[1]\n",
    "        print(\"id is: \" + id)\n",
    "\n",
    "        if episode not in episodes_to_transcripts:\n",
    "            transcript_data = get_transcript(id)\n",
    "            episodes_to_transcripts[episode] = transcript_data\n",
    "        \n",
    "        download_audio(video['link'])\n",
    "\n",
    "        files = glob.glob(f'{episode[:10]}*.json')\n",
    "        if not files:\n",
    "            raise FileNotFoundError(\"No JSON file found matching the pattern.\")\n",
    "        json_file = files[0]\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            chapters = data['chapters']\n",
    "        \n",
    "        for index, chapter in enumerate(chapters):\n",
    "            extracted_text = extract_text(episodes_to_transcripts[episode], chapter['start_time'], chapter['end_time'])\n",
    "\n",
    "            chapter_dict = {\n",
    "                \"channel\": channel,\n",
    "                \"episode\": episode,\n",
    "                \"chapter\": chapter['title'],\n",
    "                \"start_time\": chapter['start_time'],\n",
    "                \"end_time\": chapter['end_time'],\n",
    "                \"text\": extracted_text,\n",
    "                \"file_name_prefix\": f\"{episode} - {str(index).zfill(3)}\",\n",
    "                \"prev_index\": curr_base_idx + index - 1 if index > 0 else None,\n",
    "                \"next_index\": curr_base_idx + index + 1 if index < len(chapters) - 1 else None\n",
    "            }\n",
    "            all_results.append(chapter_dict)  # Add dictionaries to the list\n",
    "        curr_base_idx += len(chapters)\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(all_results, columns=columns)  # Create DataFrame from list of dictionaries\n",
    "\n",
    "# Run the script\n",
    "df = main()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ballsack.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon24s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
