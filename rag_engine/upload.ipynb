{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import os, dotenv, json\n",
    "\n",
    "\n",
    "ENV_PATH = \"../.env\"\n",
    "dotenv.load_dotenv(dotenv_path=ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(name=\"hackathon24s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#index,channel,episode,chapter,start_time,end_time,text,file_name_prefix,prev_index,next_index\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"config/data.csv\")\n",
    "sentences = []\n",
    "for i in range(len(df)):\n",
    "    if i == 128:\n",
    "        continue\n",
    "    row = df.iloc[i]\n",
    "    sentence = row[\"text\"]  \n",
    "    sentences.append(sentence)\n",
    "\n",
    "# Load AutoModel from huggingface model repository\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-l\").to(device)\n",
    "def generate_embedding(sentence):\n",
    "    # encoded_input = tokenizer(\n",
    "    #     sentence, padding=True, truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    # ).to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model.encode(sentence, convert_to_tensor=True)\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load \"config/data.csv\" as a DataFrame\n",
    "#index,channel,episode,chapter,start_time,end_time,text,file_name_prefix,prev_index,next_index\n",
    "\n",
    "# for each line in csv\n",
    "#     extract text to embe\n",
    "#     perform embedding and get vector\n",
    "#     create vectors \n",
    "#     add to upsert list \n",
    "\n",
    "upsert_list = []\n",
    "for i in range(len(df)):\n",
    "    if i == 128:\n",
    "        continue\n",
    "    row = df.iloc[i]\n",
    "    text = row[\"text\"]\n",
    "    ## run model encode on gpu\n",
    "    embedding = generate_embedding(text)\n",
    "    id = row[\"index\"]\n",
    "    ## get type of first item in embedding\n",
    "    embedding = embedding.cpu().numpy().flatten()\n",
    "    metadata = {\"index\": str(row[\"index\"]), \"channel\": str(row[\"channel\"]), \"episode\": str(row[\"episode\"]), \"chapter\": str(row[\"chapter\"]), \"start_time\": str(row[\"start_time\"]), \"end_time\": str(row[\"end_time\"]), \"text\": str(row[\"text\"]), \"file_name_prefix\": str(row[\"file_name_prefix\"]), \"prev_index\": str(row[\"prev_index\"]), \"next_index\": str(row[\"next_index\"])}\n",
    "    vector = ({\"values\": embedding, \"id\": str(id), \"metadata\": metadata})\n",
    "    upsert_list.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "{'values': array([ 0.01859549, -0.04389406,  0.03972551, ..., -0.03461152,\n",
      "        0.01294052, -0.0280786 ], dtype=float32), 'id': '1', 'metadata': {'index': '1', 'channel': 'a16z', 'episode': 'A Nuclear Comeback: Are New Reactors the Answer?', 'chapter': 'The Promise of Advanced Nuclear Reactors', 'start_time': '0.0', 'end_time': '197.0', 'text': \"they recognize we have this insatable need for energy like we're not going backwards in our energy consumption so if we're going to have new energy generation has to be clean energy deliveries of fuel are a clear vulnerability natural gas obviously can hold an entire nation hostage the typical construction timeline is really like 6 to 15 years on the big reactors right now the really exciting thing for me is that at the really far into the scale the portable micro reactors we haven't really achieved that yet you could actually produce these in a factory because they're portable you could do mass production maybe nuclear energy is a lot safer than we actually originally realized the radiation exposure from living next to a coal plant is higher than the radiation exposure from living next to a nuclear power plant 105 years from now the idea that we can't just immediately turn on a reliable and enduring power source for a community it's going to be unimaginable like it's just will be a solved problem what might surprise some people to learn is that nuclear energy accounts for 20% of the electricity in the United States but what I think will surprise very few people is to learn that this carbon-free energy source has quite the stored history over the last few decades resulting in new reactors slowing almost entirely to a halt however the past few years have been what some people might call a comeback story in 2023 we saw America's first newly built reactor come online in over three decades but we're also seeing startups build entirely new types of reactors public discourse shifting and even the US government itself recently announcing its intent to Triple nuclear power production by 2050 so in today's episode originally recorded in the heart of Washington DC back in January and a16 Z's American dynamism Summit we talk about this truly unique moment in time for nuclear energy a6c General partner David ovich joins forces with duck bernauer CEO of micro reactor company radiant and Dr Katherine Huff assistant Secretary of the office of nuclear energy as they collectively discuss nuclear Energy's role in our country's future because remember energy is vital to many of the industries that we talk about here energy pow is the data centers that run our clouds the electric cars that drive on our streets and of course is fuel for the fact iies that build our future so if anything feels certain is that we're going to need more energy not less so tune in here as this group of policy makers Founders and funders discuss why increasing our nuclear capacity should be a national priority and what it'll take to reverse this multi-decade trend oh and if you'd like to get an inside look into a16 Z's American dynamism Summit you can watch several of the stage talks from the event featuring policy makers like Congressman Jake aen CL or Senator Todd young and of course both Founders and funders building toward American dynamism you can find all of the above at az.com admit all right let's get started nuclear has quite the stored\", 'file_name_prefix': 'A Nuclear Comeback: Are New Reactors the Answer? - 001', 'prev_index': 'nan', 'next_index': '22.0'}}\n"
     ]
    }
   ],
   "source": [
    "print(len(upsert_list))\n",
    "print(upsert_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pinecone.data.index.Index'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c03d5c0cfe4489b9ed6747a6331c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 193}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(index))\n",
    "\n",
    "index.upsert(upsert_list, batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
