{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video concatenation v1\n",
    "__Author:__ Jack Friedman <br>\n",
    "__Purpose:__ Creates functions to generate clip intros and podlight intro \n",
    "__Updates since last version:__ Added LLM to make clip intros smoother "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/local/bin/ffmpeg\"  # Update this path as needed\n",
    "\n",
    "from moviepy.editor import VideoFileClip, ImageClip, AudioClip, AudioFileClip, concatenate_videoclips\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "from transformers import AutoProcessor, BarkModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'YOUR_TOKEN_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "model = BarkModel.from_pretrained(\"suno/bark\")\n",
    "\n",
    "voice_preset = \"v2/en_speaker_6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: Make clip intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A) Text prompt LLM refinement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coming up, we've got a clip about a product not working from Huberman Lab. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "# Helper function that extracts output from mistral code\n",
    "def extract_output(text):\n",
    "    pattern = r\"\\[/INST\\]\\s*\\n\\s*(.*)\"\n",
    "\n",
    "    match = re.search(pattern, text)\n",
    "\n",
    "    if match:\n",
    "        user_prompt = match.group(1).strip()\n",
    "        output = user_prompt\n",
    "    else:\n",
    "        output = \"Hi! Welcome to your custom podlight. Enjoy!\"\n",
    "    return output\n",
    "\n",
    "def create_clip_intro_prompt(podcast, chapter_description):\n",
    "    template = \"\"\"<s>[INST] Clean up the prompt sentence, adding/removing transition words around the chapter description to make the sentence clearer. Only respond with the output sentence. The prompts should all have the template \"Coming up, we've got a clip about [chapter-description] from [podcast-name]. Enjoy!\"\n",
    "\n",
    "    For example, if the chapter description is \"Big Tech's involvement in political process' from the 'a16z' podcast, you would respond with 'Coming up, we've got a clip about big tech's involvement in the political process from a16z. Enjoy!\"\n",
    "\n",
    "    For example, if the chapter description is \"Thoughts on recent TikTok legislation' from the 'All-In' podcast, you would respond with 'Coming up, we've got a clip about the recent Tiktok legislation from All-In. Enjoy!\"\n",
    "\n",
    "    For example, if the chapter description is \"Q: Would either of you ever consider running for office?' from the 'VC20' podcast, you would respond with 'Coming up, we've got a clip about running for office from All-In. Enjoy!\"\n",
    "\n",
    "    Chapter description: {chapter_description}\n",
    "    Podcast: {podcast}\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    model = HuggingFaceHub(\n",
    "        repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        task=\"text-generation\",\n",
    "        model_kwargs={\n",
    "            \"max_new_tokens\": 30,\n",
    "            \"top_k\": 30,\n",
    "            \"temperature\": 0.1,\n",
    "            \"repetition_penalty\": 1.03,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        {\"chapter_description\": RunnablePassthrough(), \"podcast\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    output = chain.invoke({\"chapter_description\": chapter_description, \"podcast\":podcast})\n",
    "    output = extract_output(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "output = create_clip_intro_prompt('Huberman Lab', \"Product Not Working\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the intro segment for a video clip given the title of the podcast and the subtitle of the chapter\n",
    "def make_clip_intro(podcast, chapter_description, model, processor, voice_preset, logo_filepath):\n",
    "    text_prompt = create_clip_intro_prompt(podcast, chapter_description)\n",
    "    inputs = processor(text_prompt, voice_preset=voice_preset)\n",
    "\n",
    "    # Run voice generator\n",
    "    audio_array = model.generate(**inputs)\n",
    "    audio_array = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "    # Create audio clip\n",
    "    sample_rate = model.generation_config.sample_rate\n",
    "    scipy.io.wavfile.write(\"audio_placeholder.wav\", rate=sample_rate, data=audio_array)\n",
    "    audio_clip = AudioFileClip(\"audio_placeholder.wav\")  # creating an AudioCLipo from the audio array was super finicky so this was a workaround\n",
    "\n",
    "     # Create an ImageClip object with the duration set to the audio clip's duration\n",
    "    image_clip = ImageClip(logo_filepath, duration=audio_clip.duration)\n",
    "\n",
    "    # Create output video\n",
    "    output_clip = image_clip.set_audio(audio_clip)\n",
    "    output_filepath = podcast + '_' + chapter_description + '_intro.mp4'\n",
    "    output_clip.write_videofile(output_filepath, fps=1) \n",
    "    return output_clip\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video a16z_Big Tech's involvement in political process_intro.mp4.\n",
      "MoviePy - Writing audio in a16z_Big Tech's involvement in political process_introTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video a16z_Big Tech's involvement in political process_intro.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready a16z_Big Tech's involvement in political process_intro.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "podcast = \"a16z\"\n",
    "chapter_description = \"Big Tech's involvement in political process\"\n",
    "VOICE_PRESET = \"v2/en_speaker_6\"\n",
    "video_clip = make_clip_intro(podcast, chapter_description, model, processor, VOICE_PRESET, \"logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2: Make show intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! We've created a podlight for you all about Google. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "def create_show_intro_prompt(user_prompt):\n",
    "    template = \"\"\"<s>[INST]Turn the user's prompt into a one sentence intro using the template: 'Hi! We've created a podlight for you all about [user's topic]. Enjoy!'\n",
    "\n",
    "    For example, if the user asks for 'podcast about AI', you would respond with 'Hi! We've created a podlight for you all about AI. Enjoy!'\n",
    "\n",
    "    User prompt: {user_prompt}[/INST]\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    model = HuggingFaceHub(\n",
    "        repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        task=\"text-generation\",\n",
    "        model_kwargs={\n",
    "            \"max_new_tokens\": 30,\n",
    "            \"top_k\": 30,\n",
    "            \"temperature\": 0.1,\n",
    "            \"repetition_penalty\": 1.03,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        {\"user_prompt\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    output = chain.invoke(user_prompt)\n",
    "    output = extract_output(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "prompt = \"Create me a podcast about Google\"\n",
    "output = create_show_intro_prompt(prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the intro segment for a video clip given the title of the podcast and the subtitle of the chapter\n",
    "def make_whole_show_intro(user_prompt, model, processor, voice_preset, logo_filepath):\n",
    "    intro_prompt = create_show_intro_prompt(user_prompt)\n",
    "    inputs = processor(intro_prompt, voice_preset=voice_preset)\n",
    "\n",
    "    # Run voice generator\n",
    "    audio_array = model.generate(**inputs)\n",
    "    audio_array = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "    # Get audio clip\n",
    "    sample_rate = model.generation_config.sample_rate\n",
    "    scipy.io.wavfile.write(\"audio_placeholder.wav\", rate=sample_rate, data=audio_array)\n",
    "    audio_clip = AudioFileClip(\"audio_placeholder.wav\")  # creating an AudioCLipo from the audio array was super finicky so this was a workaround\n",
    "\n",
    "     # Create an ImageClip object with the duration set to the audio clip's duration\n",
    "    image_clip = ImageClip(logo_filepath, duration=audio_clip.duration)\n",
    "\n",
    "    # Create output video\n",
    "    output_clip = image_clip.set_audio(audio_clip)\n",
    "    output_filepath = 'podlight_intro_clip.mp4'\n",
    "    output_clip.write_videofile(output_filepath, fps=1) \n",
    "    return output_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video podlight_intro_clip.mp4.\n",
      "MoviePy - Writing audio in podlight_intro_clipTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video podlight_intro_clip.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready podlight_intro_clip.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<moviepy.video.VideoClip.ImageClip at 0x2afd24890>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOICE_PRESET = \"v2/en_speaker_6\"\n",
    "user_prompt = 'Make me a podcast about why Carter should buy a monitor'\n",
    "make_whole_show_intro(user_prompt, model, processor, VOICE_PRESET, 'logo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"videos/waving.MOV\")\n",
    "clip2 = VideoFileClip(\"videos/fellas.MOV\")\n",
    "final_clip = concatenate_videoclips([clip1,clip2])\n",
    "final_clip.write_videofile(\"concat_v0.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
